% !TeX encoding = ISO-8859-1

\chapter{Individual work}
\label{Individual work}

In this chapter we will explain the individual work each one of us has done.

\section{Gasan Mohamad Nazer}

At first, we started to write the first chapter of the documentation. From this chapter, I wrote the introduction part, as well as the goals we have established for this project. 

After that,  I read the documentation of Pict2Text 1.0, and tested the provided application, to see its functionalities, what has been done, and what hasn't. Once I was familiar with the tool and its functionalities and flaws, I wrote the documentation section corresponding to Pict2Text 1.0 (section \ref{pict2test1}).

My next task was to research a pictogram identification algorithm. Although I had previous knowledge related to Machine Learning it was not enough to determine the correct algorithm required to solve our problem. l started by revising the basic machine learning concepts, Neural Network architectures, and computer vision in general. Later I have continued learning about Convolutional Neural Network, classification models based on that, and tools and frameworks to build machine learning models with. With that and after analyzing the ARASAAC dataset I was able to select the algorithm that best suited our needs and wrote the sections corresponding to the Machine Learning model (section \ref{Machine Learning}), including the subsections Neural Network and Convolutional Neural Network inside, and Keras (section \ref{Keras}).

When the software development methodology was chosen, I decided what type of tests we will do and wrote that part of the documentation. According to what we have decided, I also reviewed everything my partner did, as we have explained in section \ref{Kanban}.

Once we have decided which machine learning model to use for image identification, I have developed the scripts to load the pictograms. I also did the script for image rotation and the ones for brightness and colour changing. The corresponding sections in the documentation were also written by me (sections \ref{Loading ARASAAC pictograms} and \ref{Processing ARASAAC pictograms}).

As we have both tested the classification algorithm, I wrote sections \ref{First Iteration of the One-shot model} and \ref{Second Iteration of the One-shot model}, explaining the first two versions of the algorithm implementation, the results obtained by them, and the issues we have faced. At the beginning of version two, I also included one part describing which problems from the first version we were intending to solve and how.

After the second version of the pictogram identification model, we separated our work with Veronika focusing on correcting the model, while I was researching the second model for object detection. After the initial research, I have written the section \ref{Object detection vs object localization vs image classification} explaining the difference between image classification, image localization, and object detection. In the same section, I explained why we need a second model to detect and separate the pictograms from a sentence written with them. In section \ref{Object detection algorithm} I have written more about object detection. In section \ref{yolo} I have explained the YOLO model which we had later used to localize pictograms from a picture of them.

Next, I have started researching more about the different YOLO versions and how they are implemented and configured, making the first version of our detection model and its documentation (sections \ref{yolo}, \ref{YOLOimplementation} and \ref{First Iteration of YOLO}). For the first version of our model, I have labeled a custom dataset with a pictogram in the required format for the algorithm, writing the sections \ref{LabelImg} and \ref{YOLOimplementation}. The second version of our YOLO model was also implemented and written by me (section \ref{Second Iteration of YOLO}).

To integrate the two models together, I implemented an API that connects the two models so their performance can be tested. Also, the API provides endpoints for developers, who may want to use our services. After that, I wrote the corresponding documentation (section \ref{API}). Later I configured the Continuous Deployment for our API described in section \ref{Continous Deployment for Pict2Text 2.0}.

I was participating in the integration of the web application to the API creating the cropping functionality, and the way the images are saved to the file system, and the general flow of execution from provided image to returned result passing by the detection and classification models.

All of the work done with the container provided by the university was also done by me. Initially started with the idea of using Docker to dockerize our API and the web application, and also the two models we implemented, so that they could be easily deployed. This idea was discarded after several unsuccessful intentions and faced unresolvable problems. Later I have created the service of the API used in the Continuous Deployment and the unsuccessful integration of the two models.

\section{Veronika Borislavova Yankova}

The first thing I did when we started the project was to select the software development methodology. To do that, I had to research the different methodologies, evaluate the positive and negative sides of each, to finally select Kanban as the most suitable one for us. Once it was chosen, I created the Kanban board to keep everyone updated on the progress of the project, and to organize the tasks in the best way possible as Kanban requires. I added the tutors and my project partner and created the initial tasks we had established at the first meeting. After that, I described everything in the documentation (section \ref{Software development methodology}), so it will be easier for everyone to follow the methodology.

As we were going to work with pictograms, both my partner and I had to familiarize ourselves with them, what they are, what they are used for, and so on. To do so, one of us had to investigate and introduce the other to the new concepts. I started by researching what the Augmentative and Alternative Systems of Communication are, why they are necessary, and what types exist, and then dove into specific research on pictograms, in particular those provided by ARASAAC. In the end, I added that information to the documentation (sections \ref{AASC} and \ref{pictograms}).

After my partner chose the model we used for the pictogram identification, we discussed and chose which implementation to use among various he had previously found. Having the implementation, I started  reading the article and the code, in order to be able to modify the paramethers according to our dataset (the ARASAAC pictograms), and run the model with that data.

As we expected, the algorithm couldn't work with big training and testing sets, because we couldn't load that many pictures at a time. To solve that, for the second version of the algorithm, I changed it in a way it worked with mini-batches, so it didn't compute everything at once. I tested the algorithm to make sure it was working properly, and then tested it with a different number of pairs for each version in order to see which will work better for our algorithm.

In the third version of One-shot learning, I centered my effords into making the algorithm work with images of pictograms, instead of only with digital ones. For that purpouse, I took a hundred pictures of pictograms to train and test the model with pictures. As the pictograms are in png and the pictures were in jpg, I also had to make a script to convert the jpg images into png ones, so we could use them to train and test the model. 

For the fourth version of the pictogram identification algorithm, our goal was to inceese the ability of the model to recognize pictures of pictograms. To have more accurate representation of which training perform better with images, I made changes in the three datasets (training, validation and test sets). The training set was augmented and the data inside was changed from augmented digital pictograms to augmethed pictures of pictograms plus the original digital pictogram. For the validation and test sets I left only pictures so we could have more realistic results based on our goal (to recognize images of pictograms). After that, I trained and tested the model several times changing different parameters, and wrote the result in section \ref{Fourth Iteration of the One-shot model}.

As I was the one changing the one-shot learning algorithm, I wrote the parts corresponding to the second two versions of the model in the documentation. To make following the results obtained easier, I created tables in all four versions which represent the accuracy, difference in sets, and so on, in a more visual way, which also facilitated the comparison between the different versions.

To present the results we obtained from the two models, I implemented a web application, where the person can upload a picture or use some demo ones, and see the results obtained from our algorithms (the bounding boxes predicted by YOLO, and word, id and similarity score for each pictogram YOLO detected). As we have used Flask for the API, I prepared the templates that resemble HTML files in the static parts. For the styles I mainly used Bootstrap, but I also included some custom CSS styles. Last but not least, for the dynamic behavior of each of the two pages (one to upload a picture, and the other with the results), JavaScript was used. After the front end was ready, my partner and I integrated it with the API.

Then I started researching the technologies we could use for the continuous deployment, as we wanted to implement it for our project so the changes we make to the API could easily be propagated to the virtual container we have. This research is presented in sections \ref{Flask}, \ref{githubactions}, and \ref{Continous Deployment for Pict2Text 2.0}.

At the first meeting, and also later with the methodology, it was determined that every few weeks we would have a meeting with our tutors. During those, we discussed the work done for the time between the two meetings, which goals established at the previous one were achieved, and what would be the goals for the next one. We also submitted a version of the documentation before the meeting, which we discussed with the tutors and had to correct and add the new things we have done for the next time. From the very first review of the documentation, I have been in charge of correcting everything the tutors found as mistakes. I also kept section \ref{Document structure}, as well as the introduction of each chapter, updated as we added new things into the documentation.
